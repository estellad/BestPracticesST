# (PART) Analysis pipeline {-}

# Analysis pipeline {#analysis_pipeline}

This part contains chapters describing each of the main steps in an analysis pipeline for spatial transcriptomics data. The steps include loading the data, quality control, normalization, feature selection, dimensionality reduction, clustering, and interpretation. The next part ([Extended topics](#extended_topics)) contains additional steps that may be relevant for certain experiments. In [Workflows](#workflows), we also provide condensed versions of the analysis pipeline for several datasets, focusing on relatively standard methods only, and with minimal documentation, to make it easier to see how the steps fit together into a full pipeline.

Throughout the analysis pipeline, we follow the Bioconductor principle of modularity -- the pipeline uses a consistent object structure for the input and output from each step, so if you have an additional alternative method that you wish to try for one of the steps (or are developing one!), then it should be relatively simple to substitute this method and continue with the rest of the pipeline.

